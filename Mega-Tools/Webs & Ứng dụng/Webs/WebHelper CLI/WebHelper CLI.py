import os
import re
import sys
import webbrowser
import requests
from urllib.parse import urlparse
from colorama import init, Fore, Style

init(autoreset=True)

def clear():
    os.system("cls" if os.name == "nt" else "clear")

def banner():
    print(Fore.CYAN + Style.BRIGHT + "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print(Fore.CYAN + Style.BRIGHT + "â•‘          ğŸŒ WebHelper CLI          â•‘")
    print(Fore.CYAN + Style.BRIGHT + "â•‘   ğŸ› ï¸ CÃ´ng cá»¥ há»— trá»£ Web cÆ¡ báº£n     â•‘")
    print(Fore.CYAN + Style.BRIGHT + "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
    print(Fore.BLUE + Style.DIM    + "â•‘   -----Powered by SliXeR-14-----   â•‘")
    print(Fore.BLUE + Style.DIM    + "â•‘     Â© 2025 â€“ copyright reversed    â•‘")
    print(Fore.CYAN + Style.BRIGHT + "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

def normalize_url(url: str) -> str:
    parsed = urlparse(url)
    if not parsed.scheme:
        return "https://" + url
    return url

def check_status():
    url = input(Fore.YELLOW + "ğŸ”— Nháº­p URL: ").strip()
    url = normalize_url(url)
    try:
        r = requests.head(url, allow_redirects=True, timeout=8)
        print(Fore.GREEN + f"âœ… {url} â†’ HTTP {r.status_code}")
    except Exception as e:
        print(Fore.RED + f"âŒ Lá»—i: {e}")

def get_title():
    url = input(Fore.YELLOW + "ğŸ”— Nháº­p URL: ").strip()
    url = normalize_url(url)
    try:
        r = requests.get(url, timeout=8)
        m = re.search(r"<title[^>]*>(.*?)</title>", r.text, flags=re.IGNORECASE|re.DOTALL)
        title = m.group(1).strip() if m else "(khÃ´ng tÃ¬m tháº¥y tiÃªu Ä‘á»)"
        print(Fore.GREEN + f"ğŸ“„ TiÃªu Ä‘á»: {title}")
    except Exception as e:
        print(Fore.RED + f"âŒ Lá»—i: {e}")

def download_page():
    url = input(Fore.YELLOW + "ğŸ”— Nháº­p URL: ").strip()
    url = normalize_url(url)
    filename = input(Fore.CYAN + "ğŸ’¾ TÃªn file lÆ°u (máº·c Ä‘á»‹nh: index.html): ").strip() or "index.html"
    try:
        r = requests.get(url, timeout=15)
        with open(filename, "w", encoding="utf-8") as f:
            f.write(r.text)
        print(Fore.GREEN + f"âœ… ÄÃ£ lÆ°u {url} â†’ {filename}")
    except Exception as e:
        print(Fore.RED + f"âŒ Lá»—i: {e}")

def open_browser():
    url = input(Fore.YELLOW + "ğŸ”— Nháº­p URL: ").strip()
    url = normalize_url(url)
    try:
        webbrowser.open(url)
        print(Fore.GREEN + f"âœ… ÄÃ£ má»Ÿ {url} trong trÃ¬nh duyá»‡t")
    except Exception as e:
        print(Fore.RED + f"âŒ Lá»—i: {e}")

def main():
    while True:
        clear()
        banner()
        print(Fore.YELLOW + "\nğŸ“Œ MENU CHá»¨C NÄ‚NG")
        print(Fore.WHITE + "1. Kiá»ƒm tra tráº¡ng thÃ¡i website (HEAD)")
        print("2. Láº¥y tiÃªu Ä‘á» trang (HTML <title>)")
        print("3. Táº£i ná»™i dung trang vá» file")
        print("4. Má»Ÿ URL trong trÃ¬nh duyá»‡t")
        print("0. ThoÃ¡t")

        choice = input(Fore.CYAN + "\nğŸ‘‰ Chá»n chá»©c nÄƒng (0-4): ").strip()
        clear()
        banner()
        print()

        if choice == "1":
            check_status()
        elif choice == "2":
            get_title()
        elif choice == "3":
            download_page()
        elif choice == "4":
            open_browser()
        elif choice == "0":
            print(Fore.GREEN + "ğŸ‘‹ Táº¡m biá»‡t WebHelper CLI!")
            break
        else:
            print(Fore.RED + "âš ï¸ Lá»±a chá»n khÃ´ng há»£p lá»‡.")

        input(Fore.YELLOW + "\nNháº¥n Enter Ä‘á»ƒ quay láº¡i menu...")

if __name__ == "__main__":
    main()
